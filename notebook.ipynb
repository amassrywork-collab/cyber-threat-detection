{"cells":[{"source":"![cyber_photo](cyber_photo.jpg)\n\nCyber threats are a growing concern for organizations worldwide. These threats take many forms, including malware, phishing, and denial-of-service (DOS) attacks, compromising sensitive information and disrupting operations. The increasing sophistication and frequency of these attacks make it imperative for organizations to adopt advanced security measures. Traditional threat detection methods often fall short due to their inability to adapt to new and evolving threats. This is where deep learning models come into play.\n\nDeep learning models can analyze vast amounts of data and identify patterns that may not be immediately obvious to human analysts. By leveraging these models, organizations can proactively detect and mitigate cyber threats, safeguarding their sensitive information and ensuring operational continuity.\n\nAs a cybersecurity analyst, you identify and mitigate these threats. In this project, you will design and implement a deep learning model to detect cyber threats. The BETH dataset simulates real-world logs, providing a rich source of information for training and testing your model. The data has already undergone preprocessing, and we have a target label, `sus_label`, indicating whether an event is malicious (1) or benign (0).\n\nBy successfully developing this model, you will contribute to enhancing cybersecurity measures and protecting organizations from potentially devastating cyber attacks.","metadata":{},"id":"51be1f3d-e425-4d6d-9c05-fb6d98664c68","cell_type":"markdown"},{"source":"\n### The Data\n\n| Column     | Description              |\n|------------|--------------------------|\n|`processId`|The unique identifier for the process that generated the event - int64 |\n|`threadId`|ID for the thread spawning the log - int64|\n|`parentProcessId`|Label for the process spawning this log - int64|\n|`userId`|ID of user spawning the log|Numerical - int64|\n|`mountNamespace`|Mounting restrictions the process log works within - int64|\n|`argsNum`|Number of arguments passed to the event - int64|\n|`returnValue`|Value returned from the event log (usually 0) - int64|\n|`sus_label`|Binary label as suspicous event (1 is suspicious, 0 is not) - int64|\n\nMore information on the dataset: [BETH dataset](accreditation.md)","metadata":{},"id":"8811256f-f887-4867-903e-837238fbb648","cell_type":"markdown"},{"source":"# ===============================\n# 1. Import libraries\n# ===============================\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torchmetrics\nimport pandas as pd","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1764094671913,"lastExecutedByKernel":"caef2482-fd03-43c4-a9df-ee0300975011","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# ===============================\n# 1. Import libraries\n# ===============================\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torchmetrics\nimport pandas as pd"},"id":"75892dec-9424-4c92-bf8e-2f9847b7d7cd","cell_type":"code","execution_count":12,"outputs":[]},{"source":"# ===============================\n# 2. Load preprocessed CSV files\n# ===============================\ntrain_df = pd.read_csv('labelled_train.csv')\nval_df   = pd.read_csv('labelled_validation.csv')\ntest_df  = pd.read_csv('labelled_test.csv')","metadata":{"executionCancelledAt":null,"executionTime":365,"lastExecutedAt":1764094672278,"lastExecutedByKernel":"caef2482-fd03-43c4-a9df-ee0300975011","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# ===============================\n# 2. Load preprocessed CSV files\n# ===============================\ntrain_df = pd.read_csv('labelled_train.csv')\nval_df   = pd.read_csv('labelled_validation.csv')\ntest_df  = pd.read_csv('labelled_test.csv')"},"id":"e52e231f-71b5-4dfc-81f9-a3321ff78047","cell_type":"code","execution_count":13,"outputs":[]},{"source":"# ===============================\n# 3. Split features and labels\n# ===============================\nX_train = train_df.drop(columns=['sus_label']).values\ny_train = train_df['sus_label'].values\n\nX_val = val_df.drop(columns=['sus_label']).values\ny_val = val_df['sus_label'].values","metadata":{"executionCancelledAt":null,"executionTime":58,"lastExecutedAt":1764094672337,"lastExecutedByKernel":"caef2482-fd03-43c4-a9df-ee0300975011","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# ===============================\n# 3. Split features and labels\n# ===============================\nX_train = train_df.drop(columns=['sus_label']).values\ny_train = train_df['sus_label'].values\n\nX_val = val_df.drop(columns=['sus_label']).values\ny_val = val_df['sus_label'].values"},"id":"6b7ee389-d5ef-4c4d-bc7a-4d0be0e1c6e1","cell_type":"code","execution_count":14,"outputs":[]},{"source":"# ===============================\n# 4. Convert to PyTorch tensors\n# ===============================\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\n\nX_val   = torch.tensor(X_val,   dtype=torch.float32)\ny_val   = torch.tensor(y_val,   dtype=torch.long)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1764094672389,"lastExecutedByKernel":"caef2482-fd03-43c4-a9df-ee0300975011","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# ===============================\n# 4. Convert to PyTorch tensors\n# ===============================\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\n\nX_val   = torch.tensor(X_val,   dtype=torch.float32)\ny_val   = torch.tensor(y_val,   dtype=torch.long)"},"cell_type":"code","id":"a5978a2d-a027-4e90-8b76-e0c13b42798e","outputs":[],"execution_count":15},{"source":"# ===============================\n# 5. Create TensorDataset + DataLoader\n# ===============================\ntrain_ds = TensorDataset(X_train, y_train)\nval_ds   = TensorDataset(X_val, y_val)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader   = DataLoader(val_ds, batch_size=32, shuffle=False)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1764094672445,"lastExecutedByKernel":"caef2482-fd03-43c4-a9df-ee0300975011","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# ===============================\n# 5. Create TensorDataset + DataLoader\n# ===============================\ntrain_ds = TensorDataset(X_train, y_train)\nval_ds   = TensorDataset(X_val, y_val)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader   = DataLoader(val_ds, batch_size=32, shuffle=False)"},"cell_type":"code","id":"db51de49-85d8-4521-9c96-ee161c620f95","outputs":[],"execution_count":16},{"source":"# ===============================\n# 6. Define Model\n# ===============================\ninput_dim = X_train.shape[1]   # number of columns\n\nmodel = nn.Sequential(\n    nn.Linear(input_dim, 32),\n    nn.ReLU(),\n    nn.Linear(32, 16),\n    nn.ReLU(),\n    nn.Linear(16, 2)   # binary classification → 2 outputs\n)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1764094672497,"lastExecutedByKernel":"caef2482-fd03-43c4-a9df-ee0300975011","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# ===============================\n# 6. Define Model\n# ===============================\ninput_dim = X_train.shape[1]   # number of columns\n\nmodel = nn.Sequential(\n    nn.Linear(input_dim, 32),\n    nn.ReLU(),\n    nn.Linear(32, 16),\n    nn.ReLU(),\n    nn.Linear(16, 2)   # binary classification → 2 outputs\n)"},"cell_type":"code","id":"71aa6c60-f893-4a47-b93c-130a87563954","outputs":[],"execution_count":17},{"source":"# ===============================\n# 7. Loss + Optimizer\n# ===============================\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1764094672549,"lastExecutedByKernel":"caef2482-fd03-43c4-a9df-ee0300975011","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# ===============================\n# 7. Loss + Optimizer\n# ===============================\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)"},"cell_type":"code","id":"b6f6dba7-51e3-4daa-bbce-a40ab7cfc370","outputs":[],"execution_count":18},{"source":"# ===============================\n# 8. Accuracy Metric\n# ===============================\naccuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1764094672605,"lastExecutedByKernel":"caef2482-fd03-43c4-a9df-ee0300975011","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# ===============================\n# 8. Accuracy Metric\n# ===============================\naccuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)"},"cell_type":"code","id":"014c178e-fadd-4595-b689-0aadc9432775","outputs":[],"execution_count":19},{"source":"# ===============================\n# 9. Training Loop (10 epochs)\n# ===============================\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n\n    # ---- Training ----\n    model.train()\n    for features, labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model(features)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n    # ---- Validation ----\n    model.eval()\n    accuracy_metric.reset()\n\n    with torch.no_grad():\n        for features, labels in val_loader:\n            outputs = model(features)\n            preds = outputs.argmax(dim=-1)\n            accuracy_metric.update(preds, labels)\n\n    val_accuracy = accuracy_metric.compute().item()\n\n    print(f\"Epoch {epoch+1}/{num_epochs} | Validation Accuracy = {val_accuracy:.4f}\")","metadata":{"executionCancelledAt":null,"executionTime":1020919,"lastExecutedAt":1764095693525,"lastExecutedByKernel":"caef2482-fd03-43c4-a9df-ee0300975011","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# ===============================\n# 9. Training Loop (10 epochs)\n# ===============================\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n\n    # ---- Training ----\n    model.train()\n    for features, labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model(features)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n    # ---- Validation ----\n    model.eval()\n    accuracy_metric.reset()\n\n    with torch.no_grad():\n        for features, labels in val_loader:\n            outputs = model(features)\n            preds = outputs.argmax(dim=-1)\n            accuracy_metric.update(preds, labels)\n\n    val_accuracy = accuracy_metric.compute().item()\n\n    print(f\"Epoch {epoch+1}/{num_epochs} | Validation Accuracy = {val_accuracy:.4f}\")","outputsMetadata":{"0":{"height":227,"type":"stream"}}},"cell_type":"code","id":"f84db71d-a8cd-4f84-a0e1-8a69cd35378c","outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/10 | Validation Accuracy = 0.9958\nEpoch 2/10 | Validation Accuracy = 0.9958\nEpoch 3/10 | Validation Accuracy = 0.9958\nEpoch 4/10 | Validation Accuracy = 0.9958\nEpoch 5/10 | Validation Accuracy = 0.9958\nEpoch 6/10 | Validation Accuracy = 0.9958\nEpoch 7/10 | Validation Accuracy = 0.9958\nEpoch 8/10 | Validation Accuracy = 0.9958\nEpoch 9/10 | Validation Accuracy = 0.9958\nEpoch 10/10 | Validation Accuracy = 0.9958\n"}],"execution_count":20},{"source":"# ===============================\n# Final required output variable\n# (The project needs val_accuracy defined)\n# ===============================\nval_accuracy = float(val_accuracy)\nval_accuracy","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1764095693578,"lastExecutedByKernel":"caef2482-fd03-43c4-a9df-ee0300975011","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# ===============================\n# Final required output variable\n# (The project needs val_accuracy defined)\n# ===============================\nval_accuracy = float(val_accuracy)\nval_accuracy"},"cell_type":"code","id":"ce183741-e23e-43c4-9f03-d4d47dc48d1e","outputs":[{"output_type":"execute_result","data":{"text/plain":"0.9958405494689941"},"metadata":{},"execution_count":21}],"execution_count":21}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}